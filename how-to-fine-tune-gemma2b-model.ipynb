{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/puneetkoundal/fine-tune-gemma2b-model-using-keras-using-lora?scriptVersionId=217951826\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"15bf16b4","metadata":{"papermill":{"duration":0.004457,"end_time":"2025-01-16T17:53:10.870719","exception":false,"start_time":"2025-01-16T17:53:10.866262","status":"completed"},"tags":[]},"source":["# 1.INTRODUCTION"]},{"cell_type":"markdown","id":"71c023ab","metadata":{"papermill":{"duration":0.003418,"end_time":"2025-01-16T17:53:10.878116","exception":false,"start_time":"2025-01-16T17:53:10.874698","status":"completed"},"tags":[]},"source":["Gemma2b is a state-of-the-art transformer-based model designed to handle a wide range of natural language processing (NLP) tasks. It belongs to the family of large language models that leverage vast amounts of training data and computational power to achieve remarkable performance across tasks like:\n","\n","Text Classification: Assigning categories or labels to text (e.g., sentiment analysis, topic detection).\n","Text Generation: Generating coherent and contextually appropriate text (e.g., conversational agents, content creation).\n","Summarization: Producing concise summaries from long documents or articles.\n","Translation: Translating text between languages.\n","Question Answering: Answering questions based on a given context or dataset.\n","The model has been pretrained on massive text datasets, capturing a deep understanding of language structure, grammar, semantics, and even domain-specific knowledge."]},{"cell_type":"markdown","id":"70db8b29","metadata":{"papermill":{"duration":0.003306,"end_time":"2025-01-16T17:53:10.884974","exception":false,"start_time":"2025-01-16T17:53:10.881668","status":"completed"},"tags":[]},"source":["# 2.Prerequisites"]},{"cell_type":"markdown","id":"060a684c","metadata":{"papermill":{"duration":0.003182,"end_time":"2025-01-16T17:53:10.891718","exception":false,"start_time":"2025-01-16T17:53:10.888536","status":"completed"},"tags":[]},"source":["1. Sign in to Kaggle\n","Visit Kaggle.\n","Log in to your Kaggle account.\n","2. Access API Credentials\n","Click on your profile picture in the top-right corner.\n","From the dropdown menu, select \"Account\".\n","Scroll down to the \"API\" section.\n","Click the \"Create New API Token\" button.\n","3. Download kaggle.json\n","This will download a file named kaggle.json containing your Kaggle username and Kaggle API key in JSON format.\n","4. Use Credentials in Code\n","You can directly upload kaggle.json to Colab and set environment variables:"]},{"cell_type":"code","execution_count":1,"id":"5a9a13c0","metadata":{"execution":{"iopub.execute_input":"2025-01-16T17:53:10.900474Z","iopub.status.busy":"2025-01-16T17:53:10.900083Z","iopub.status.idle":"2025-01-16T17:53:10.910221Z","shell.execute_reply":"2025-01-16T17:53:10.90943Z"},"papermill":{"duration":0.016949,"end_time":"2025-01-16T17:53:10.912174","exception":false,"start_time":"2025-01-16T17:53:10.895225","status":"completed"},"tags":[]},"outputs":[],"source":["\n","import os\n","import json\n","\n","# Load kaggle.json\n","with open('/kaggle/input/kaggle-json/kaggle (1).json', 'r') as f:\n","    kaggle_data = json.load(f)\n","\n","# Set environment variables\n","os.environ['KAGGLE_USERNAME'] = kaggle_data['username']\n","os.environ['KAGGLE_KEY'] = kaggle_data['key']\n","\n","#print(\"Kaggle credentials successfully set!\")      #UNCOM\n"]},{"cell_type":"code","execution_count":2,"id":"3f579310","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2025-01-16T17:53:10.921273Z","iopub.status.busy":"2025-01-16T17:53:10.920971Z","iopub.status.idle":"2025-01-16T17:53:10.92577Z","shell.execute_reply":"2025-01-16T17:53:10.924807Z"},"papermill":{"duration":0.010656,"end_time":"2025-01-16T17:53:10.927255","exception":false,"start_time":"2025-01-16T17:53:10.916599","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import json\n","\n","# Load kaggle.json\n","with open('/kaggle/input/kaggle-json/kaggle (1).json', 'r') as f:\n","    kaggle_data = json.load(f)\n","\n","# Set environment variables\n","os.environ['KAGGLE_USERNAME'] = kaggle_data['username']\n","os.environ['KAGGLE_KEY'] = kaggle_data['key']\n","\n","#print(\"Kaggle credentials successfully set!\")      #UNCOM\n"]},{"cell_type":"markdown","id":"5fa471b1","metadata":{"papermill":{"duration":0.003498,"end_time":"2025-01-16T17:53:10.934566","exception":false,"start_time":"2025-01-16T17:53:10.931068","status":"completed"},"tags":[]},"source":["# 3.Setting Up the Environment"]},{"cell_type":"markdown","id":"05147fc9","metadata":{"papermill":{"duration":0.00349,"end_time":"2025-01-16T17:53:10.941681","exception":false,"start_time":"2025-01-16T17:53:10.938191","status":"completed"},"tags":[]},"source":["Libraries Overview:\n","os: Provides functions to interact with the operating system, such as file handling and environment variable management.\n","enum: Allows for the creation of enumerations, which are a set of symbolic names bound to unique values.\n","re: Provides regular expression matching operations for pattern matching in strings.\n","string: Contains string constants and classes for string manipulation.\n","chex: A utility library for JAX-related development that helps with debugging, type checking, and testing.\n","jax: A library for high-performance numerical computing and machine learning using automatic differentiation and GPU/TPU acceleration.\n","jax.numpy: Provides a NumPy-like interface for tensor operations using JAX.\n","optax: A gradient processing and optimization library for JAX, commonly used for defining and applying optimization algorithms.\n","tensorflow: A framework for building and deploying machine learning models.\n","tensorflow_datasets: A library providing easy access to a wide variety of datasets for machine learning experiments."]},{"cell_type":"code","execution_count":3,"id":"e3ddbb07","metadata":{"execution":{"iopub.execute_input":"2025-01-16T17:53:10.950261Z","iopub.status.busy":"2025-01-16T17:53:10.949914Z","iopub.status.idle":"2025-01-16T17:53:23.047985Z","shell.execute_reply":"2025-01-16T17:53:23.046932Z"},"papermill":{"duration":12.104607,"end_time":"2025-01-16T17:53:23.050014","exception":false,"start_time":"2025-01-16T17:53:10.945407","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h"]}],"source":["# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n","!pip install -q -U keras-nlp\n","!pip install -q -U \"keras>=3\""]},{"cell_type":"code","execution_count":4,"id":"cfecf138","metadata":{"execution":{"iopub.execute_input":"2025-01-16T17:53:23.059514Z","iopub.status.busy":"2025-01-16T17:53:23.059183Z","iopub.status.idle":"2025-01-16T17:53:23.063446Z","shell.execute_reply":"2025-01-16T17:53:23.062519Z"},"papermill":{"duration":0.010688,"end_time":"2025-01-16T17:53:23.065168","exception":false,"start_time":"2025-01-16T17:53:23.05448","status":"completed"},"tags":[]},"outputs":[],"source":["os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n","# Avoid memory fragmentation on JAX backend.\n","os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""]},{"cell_type":"markdown","id":"d98d632a","metadata":{"papermill":{"duration":0.003593,"end_time":"2025-01-16T17:53:23.072734","exception":false,"start_time":"2025-01-16T17:53:23.069141","status":"completed"},"tags":[]},"source":[]},{"cell_type":"code","execution_count":5,"id":"1ea1b701","metadata":{"execution":{"iopub.execute_input":"2025-01-16T17:53:23.081234Z","iopub.status.busy":"2025-01-16T17:53:23.080921Z","iopub.status.idle":"2025-01-16T17:53:35.125912Z","shell.execute_reply":"2025-01-16T17:53:35.12482Z"},"papermill":{"duration":12.05137,"end_time":"2025-01-16T17:53:35.127915","exception":false,"start_time":"2025-01-16T17:53:23.076545","status":"completed"},"tags":[]},"outputs":[],"source":["import keras\n","import keras_nlp"]},{"cell_type":"markdown","id":"40036024","metadata":{"papermill":{"duration":0.003752,"end_time":"2025-01-16T17:53:35.135877","exception":false,"start_time":"2025-01-16T17:53:35.132125","status":"completed"},"tags":[]},"source":["# 4.Load the Gemma model"]},{"cell_type":"code","execution_count":6,"id":"a5f79575","metadata":{"execution":{"iopub.execute_input":"2025-01-16T17:53:35.144867Z","iopub.status.busy":"2025-01-16T17:53:35.144275Z","iopub.status.idle":"2025-01-16T17:55:02.768643Z","shell.execute_reply":"2025-01-16T17:55:02.767552Z"},"papermill":{"duration":87.630971,"end_time":"2025-01-16T17:55:02.77072","exception":false,"start_time":"2025-01-16T17:53:35.139749","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n","└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n","│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n","├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n","│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n","│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n","└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_2b_en\")\n","gemma_lm.summary()"]},{"cell_type":"code","execution_count":null,"id":"d6cd3190","metadata":{"papermill":{"duration":0.005697,"end_time":"2025-01-16T17:55:02.782639","exception":false,"start_time":"2025-01-16T17:55:02.776942","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"aebfd67e","metadata":{"papermill":{"duration":0.005683,"end_time":"2025-01-16T17:55:02.793907","exception":false,"start_time":"2025-01-16T17:55:02.788224","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"51897055","metadata":{"papermill":{"duration":0.006057,"end_time":"2025-01-16T17:55:02.805746","exception":false,"start_time":"2025-01-16T17:55:02.799689","status":"completed"},"tags":[]},"outputs":[],"source":["\n"]},{"cell_type":"markdown","id":"49bb1eaa","metadata":{"papermill":{"duration":0.005568,"end_time":"2025-01-16T17:55:02.817245","exception":false,"start_time":"2025-01-16T17:55:02.811677","status":"completed"},"tags":[]},"source":["# 5. Data prepration"]},{"cell_type":"code","execution_count":null,"id":"1c5e3afc","metadata":{"papermill":{"duration":0.005391,"end_time":"2025-01-16T17:55:02.829093","exception":false,"start_time":"2025-01-16T17:55:02.823702","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"26852926","metadata":{"papermill":{"duration":0.005536,"end_time":"2025-01-16T17:55:02.840388","exception":false,"start_time":"2025-01-16T17:55:02.834852","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","id":"97103e35","metadata":{"papermill":{"duration":0.005662,"end_time":"2025-01-16T17:55:02.851945","exception":false,"start_time":"2025-01-16T17:55:02.846283","status":"completed"},"tags":[]},"source":[" This notebook is a work-in-progress and not yet complete.\n","\n"," \n"," Certain sections may be unfinished, and results may not be final.\n","\n"," \n"," I will continue to update and refine the notebook."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6469422,"sourceId":10451252,"sourceType":"datasetVersion"},{"datasetId":6481218,"sourceId":10467893,"sourceType":"datasetVersion"},{"modelId":78150,"modelInstanceId":72244,"sourceId":85984,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":117.97338,"end_time":"2025-01-16T17:55:06.229753","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-16T17:53:08.256373","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}